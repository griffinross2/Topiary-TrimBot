{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a crude method of detecting the green pixels of a plant.\n",
    "Assumptions:\n",
    "1. The plant is green (specifically, close to this arbitrarily chosen color: 44, 128, 31)\n",
    "2. The plant fills 35% of the image frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np\n",
    "\n",
    "# Import the image\n",
    "img = Image.open(\"image324x324outside.jpg\")\n",
    "\n",
    "# Define constants\n",
    "START_COLOR = (44, 128, 31)         # A magic green color\n",
    "THRESHOLD = 70                      # A threshold, in euclidean distance, for color matching\n",
    "PLANT_FRACTION = 0.35               # Fraction of the image filled by the plant\n",
    "PLANT_FRACTION_TOLERANCE = 0.01     # Tolerance for the plant fraction\n",
    "MAX_ITERATIONS = 20                 # Max iterations for search\n",
    "CONNECTED_BOX_SIZE = 7              # Minimum size of a box to consider for connectivity\n",
    "\n",
    "threshold_squared = THRESHOLD * THRESHOLD\n",
    "\n",
    "# Define a function that takes a comparison color and determines the fraction of pixels close to it\n",
    "def compare_image_to_color(image, color):\n",
    "    width, height = image.size\n",
    "    pixels = image.load()\n",
    "    count = 0\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            r, g, b = pixels[x, y][:3]  # Ignore alpha channel if present\n",
    "            dr = r - color[0]\n",
    "            dg = g - color[1]\n",
    "            db = b - color[2]\n",
    "            distance_squared = dr * dr + dg * dg + db * db\n",
    "\n",
    "            if distance_squared <= threshold_squared:\n",
    "                count += 1\n",
    "\n",
    "    return count / (width * height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to compensate for the overall brightness of the image, we should adjust the magic color value in value (HSV) until we get within our 35% metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Value 0.25098039215686274, Fraction 0.311280673677793\n",
      "Iteration 2: Value 0.3764705882352941, Fraction 0.3307041609510745\n",
      "Iteration 3: Value 0.3137254901960784, Fraction 0.3330094497789971\n",
      "Iteration 4: Value 0.34509803921568627, Fraction 0.3378581771071483\n",
      "Iteration 5: Value 0.3607843137254902, Fraction 0.33582914189910074\n",
      "Iteration 6: Value 0.3529411764705882, Fraction 0.3361816034141137\n",
      "Iteration 7: Value 0.35686274509803917, Fraction 0.34034445968602345\n",
      "Best match color: 44, 128, 31\n",
      "Best match fraction: 0.34034445968602345\n"
     ]
    }
   ],
   "source": [
    "match_color = colorsys.rgb_to_hsv(START_COLOR[0]/255, START_COLOR[1]/255, START_COLOR[2]/255)\n",
    "\n",
    "match_fraction = -100.0\n",
    "\n",
    "min_value = 0.0\n",
    "curr_value = match_color[2]\n",
    "max_value = 1.0\n",
    "\n",
    "iter_count = 0\n",
    "\n",
    "# Binary-ish search to the best value\n",
    "while abs(match_fraction - PLANT_FRACTION) > PLANT_FRACTION_TOLERANCE and abs(max_value - min_value) > 0.005 and iter_count < MAX_ITERATIONS:\n",
    "    iter_count += 1\n",
    "\n",
    "    color_below = (curr_value - min_value) / 2 + min_value\n",
    "    color_above = (max_value - curr_value) / 2 + curr_value\n",
    "\n",
    "    rgb_below = colorsys.hsv_to_rgb(match_color[0], match_color[1], color_below)\n",
    "    rgb_above = colorsys.hsv_to_rgb(match_color[0], match_color[1], color_above)\n",
    "\n",
    "    frac_below = compare_image_to_color(img, (int(rgb_below[0]*255), int(rgb_below[1]*255), int(rgb_below[2]*255)))\n",
    "    frac_above = compare_image_to_color(img, (int(rgb_above[0]*255), int(rgb_above[1]*255), int(rgb_above[2]*255)))\n",
    "\n",
    "    if abs(frac_below - PLANT_FRACTION) < abs(frac_above - PLANT_FRACTION):\n",
    "        # Closer by decreasing value\n",
    "        max_value = curr_value\n",
    "        curr_value = color_below\n",
    "        match_fraction = frac_below\n",
    "    else:\n",
    "        # Closer by increasing value\n",
    "        min_value = curr_value\n",
    "        curr_value = color_above\n",
    "        match_fraction = frac_above\n",
    "\n",
    "    print(f\"Iteration {iter_count}: Value {curr_value}, Fraction {match_fraction}\")\n",
    "\n",
    "match_color_rgb = colorsys.hsv_to_rgb(match_color[0], match_color[1], match_color[2])\n",
    "\n",
    "print(f\"Best match color: {int(match_color_rgb[0]*255)}, {int(match_color_rgb[1]*255)}, {int(match_color_rgb[2]*255)}\")\n",
    "print(f\"Best match fraction: {match_fraction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we make a matrix of locations meeting the conditions to be a \"plant pixel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a comparison color and replaces the pixels close to it with red\n",
    "def build_plant_pixel_matrix(image, color):\n",
    "    width, height = image.size\n",
    "    pixels = image.load()\n",
    "    mat_out = np.zeros((height, width), dtype=bool)\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            r, g, b = pixels[x, y][:3]  # Ignore alpha channel if present\n",
    "            dr = r - color[0]\n",
    "            dg = g - color[1]\n",
    "            db = b - color[2]\n",
    "            distance_squared = dr * dr + dg * dg + db * db\n",
    "\n",
    "            if distance_squared <= threshold_squared:\n",
    "                mat_out[x, y] = True\n",
    "\n",
    "    return mat_out\n",
    "\n",
    "# Create a copy of the original image to show the detected plant\n",
    "plant_mat = build_plant_pixel_matrix(img, (int(match_color_rgb[0]*255), int(match_color_rgb[1]*255), int(match_color_rgb[2]*255)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to find a way to discard points that are disconnected from the actual plant. We will consider a point to be connected if we can draw a box of any size larger than a threshold size, and the box is filled at least halfway by plant points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_mat_second_pass = np.zeros(plant_mat.shape, dtype=bool)\n",
    "\n",
    "for row in range(plant_mat.shape[0]):\n",
    "    for col in range(plant_mat.shape[1]):\n",
    "        if plant_mat[row, col]:\n",
    "            # Check boxes for connectivity\n",
    "            for box_size in range(CONNECTED_BOX_SIZE, min(plant_mat.shape[0], plant_mat.shape[1])//2):\n",
    "                half_box = box_size // 2\n",
    "                r_start = max(0, row - half_box)\n",
    "                r_end = min(plant_mat.shape[0], row + half_box)\n",
    "                c_start = max(0, col - half_box)\n",
    "                c_end = min(plant_mat.shape[1], col + half_box)\n",
    "                \n",
    "                box = plant_mat[r_start:r_end, c_start:c_end]\n",
    "                box_area = box.size\n",
    "                box_plant_count = np.sum(box)\n",
    "\n",
    "                if box_area > 0 and (box_plant_count / box_area) >= 0.5:\n",
    "                    # Connected point\n",
    "                    plant_mat_second_pass[row, col] = True\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now display the results and overlay the found pixels onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "first_pass_img_array = (plant_mat.astype(np.uint8) * 255).transpose()\n",
    "img_first_pass = Image.fromarray(first_pass_img_array)\n",
    "\n",
    "second_pass_img_array = (plant_mat_second_pass.astype(np.uint8) * 255).transpose()\n",
    "img_second_pass = Image.fromarray(second_pass_img_array)\n",
    "\n",
    "overlay_img = img.copy()\n",
    "for x in range(overlay_img.width):\n",
    "    for y in range(overlay_img.height):\n",
    "        if plant_mat_second_pass[x, y]:\n",
    "            overlay_img.putpixel((x, y), (255, 0, 0))  # Mark detected plant pixels in red\n",
    "\n",
    "img_first_pass.show()\n",
    "img_second_pass.show()\n",
    "overlay_img.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
